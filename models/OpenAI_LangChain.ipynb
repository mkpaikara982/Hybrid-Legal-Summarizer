{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manish\\.conda\\envs\\capstone\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Manish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#loading Librraries\n",
    "from datasets import load_dataset\n",
    "from rouge_score import rouge_scorer\n",
    "import csv\n",
    "import time\n",
    "import gc\n",
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "# Load the dataset\n",
    "multi_lexsum = load_dataset(\"allenai/multi_lexsum\", name=\"v20230518\")\n",
    "instances_list = list(multi_lexsum[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manish\\.conda\\envs\\capstone\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#OpenaAi api key removed for security. You can add your own or contact mp420@uowmail.edu.au [Manish Paikara 7640432] for the one used in the project\n",
    "llm = OpenAI(openai_api_key=\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text(index):\n",
    "    entry = multi_lexsum['validation'][index]\n",
    "    document_text = entry['sources']\n",
    "    document_string = \"\".join(document_text)\n",
    "    return document_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_long(index):\n",
    "    entry = multi_lexsum['validation'][index]\n",
    "    summary_text = entry['summary/long']\n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Case_ID(index):\n",
    "    entry = multi_lexsum['validation'][index]\n",
    "    case_id = entry['id']\n",
    "    return case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JI-OH-0011'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Case_ID(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_openai(document_string):\n",
    "    #\n",
    "    # Optimize the chunk size and overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=500, length_function=len)\n",
    "    text_chunks = text_splitter.split_text(document_string)\n",
    "    print(len(text_chunks))\n",
    "\n",
    "    # Create a list of LangChain documents from the chunks\n",
    "    documents = [Document(page_content=chunk) for chunk in text_chunks]\n",
    "\n",
    "    # Concise map prompt template\n",
    "    map_template = \"Summarize these {documents}, focusing on key legal arguments, evidence, claims, and judgments described in each segment.\"\n",
    "    map_prompt = PromptTemplate.from_template(map_template)\n",
    "    map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "    # Concise reduce prompt template\n",
    "    reduce_template = \"\"\"Using the {doc_summaries} generate a summary that describes the entire document from a legal viewpoint\"\"\"\n",
    "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    "    )\n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        token_max=4000,\n",
    "    )\n",
    "\n",
    "    map_reduce_chain = MapReduceDocumentsChain(\n",
    "        llm_chain=map_chain,\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        document_variable_name=\"documents\",\n",
    "        return_intermediate_steps=False,\n",
    "    )\n",
    "\n",
    "    def summarize_pdf(documents):\n",
    "        return map_reduce_chain.run(documents)\n",
    "\n",
    "    result_summary = summarize_pdf(documents)\n",
    "    return result_summary\n",
    "\n",
    "# print(get_summary_openai(document_string))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial code to check functionality\n",
    "# summary_openai = get_summary_openai(document_string)\n",
    "# print(summary_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PA-CA-0002'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entry = multi_lexsum['validation'][17]\n",
    "# case_id = entry[\"id\"]\n",
    "# case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_instances(iteration, csv_file_path='rogue_score_openai.csv'):\n",
    "    refrence_summary = get_summary_long(iteration)\n",
    "    generated_summary = get_summary_openai(str(get_full_text(iteration)))\n",
    "\n",
    "    # print(refrence_summary)\n",
    "    # print(generated_summary)\n",
    "\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    score = scorer.score(generated_summary, refrence_summary )\n",
    "\n",
    "    # print(score['rouge1'].precision)\n",
    "    # print(score['rouge1'].recall)\n",
    "    # print(score['rouge1'].fmeasure)\n",
    "    # print(score['rouge2'].precision)\n",
    "    # print(score['rouge2'].recall)\n",
    "    # print(score['rouge2'].fmeasure)\n",
    "    # print(score['rougeL'].precision)\n",
    "    # print(score['rougeL'].recall)\n",
    "    # print(score['rougeL'].fmeasure)\n",
    "\n",
    "    with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'Case_ID', 'refrence_summary','generated_summary',\n",
    "            'ROUGE-1_Precision', 'ROUGE-1_Recall', 'ROUGE-1_F1',\n",
    "            'ROUGE-2_Precision', 'ROUGE-2_Recall', 'ROUGE-2_F1',\n",
    "            'ROUGE-L_Precision', 'ROUGE-L_Recall', 'ROUGE-L_F1',\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        data = {\n",
    "        'Case_ID': get_Case_ID(iteration),\n",
    "        'refrence_summary': refrence_summary,\n",
    "        'generated_summary': generated_summary,\n",
    "        'ROUGE-1_Precision': round(score['rouge1'].precision, 4),\n",
    "        'ROUGE-1_Recall': round(score['rouge1'].recall, 4),\n",
    "        'ROUGE-1_F1': round(score['rouge1'].fmeasure, 4),\n",
    "        'ROUGE-2_Precision': round(score['rouge2'].precision, 4),\n",
    "        'ROUGE-2_Recall': round(score['rouge2'].recall, 4),\n",
    "        'ROUGE-2_F1': round(score['rouge2'].fmeasure, 4),\n",
    "        'ROUGE-L_Precision': round(score['rougeL'].precision, 4),\n",
    "        'ROUGE-L_Recall': round(score['rougeL'].recall, 4),\n",
    "        'ROUGE-L_F1': round(score['rougeL'].fmeasure, 4),\n",
    "        }\n",
    "        # print(data)  # Debugging line to check the output\n",
    "        writer.writerow(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(start_iteration=0, end_iteration=250, iteration_file='iteration_tracker.txt'):\n",
    "    try:\n",
    "        # Check the last iteration completed from the file\n",
    "        with open(iteration_file, 'r') as file:\n",
    "            start_iteration = int(file.read().strip()) + 1\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, start from the provided or default start_iteration\n",
    "        pass\n",
    "\n",
    "    for iteration in range(start_iteration, end_iteration):\n",
    "        print(f\"Processing iteration {iteration}\")\n",
    "        process_instances(iteration)\n",
    "        \n",
    "        # Update the iteration file with the last completed iteration\n",
    "        with open(iteration_file, 'w') as file:\n",
    "            file.write(str(iteration))\n",
    "        print(f\"Completed iteration {iteration}, resuming will start at iteration {iteration + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
